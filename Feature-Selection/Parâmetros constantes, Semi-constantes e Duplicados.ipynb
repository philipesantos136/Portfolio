{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                                           (Pressione Ctrl + Click)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/169rmtyEwRg4YXrWxkpUfssPbWaAQpnxK)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No aprendizado de máquina e na estatística, a seleção de recursos, também conhecida como seleção de variáveis, seleção de atributos ou seleção de subconjuntos de variáveis, é o processo de seleção de um subconjunto de recursos relevantes (variáveis, preditores) para uso na construção do modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " As técnicas de seleção de recursos são usadas por vários motivos:\n",
    "     * simplificação de modelos para facilitar a interpretação por pesquisadores / usuários;\n",
    "     * tempo de treinamento mais curto;\n",
    "     * reduz o processo de overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## O que seria selecionar parâmetros?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parâmetros Selecionados com a utilização de filtros, podem ser usados como entrada de qualquer modelo de machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os métodos se diferem aos tipos de dados:\n",
    "\n",
    "Univariado   -> Análise de cada variável separadamente\n",
    "\n",
    "Bivariado    -> Método de análise de duas variáveis (causa/efeito)\n",
    "\n",
    "Multivariado -> Métodos de análise de relações de múltiplas variáveis dependentes ou independentes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qual o melhor Método?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como tudo na vida, não existe o modelo perfeito mas o que se adequa melhor aos seus dados. Como cientista de dados, uma de nossas \n",
    "funções é testar o máximo de hipóteses para melhorar o desempenho geral do aprendizado, evitando o overfitting e estudando a relaçao\n",
    "os dados sempre da melhor forma."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download dos Dados\n",
    "* https://github.com/philipesantos136/Portfolio/tree/master/Feature-Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O Objetivo principal dessa base de dados é criar um modelo que prevê disponibilização de crédito para os clientesdo banco, os que tiveram como TARGET = 1, são os que preencheram o requisito de liberação de crédito."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import VarianceThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "!pip install -q scikit-plot\n",
    "import scikitplot as skplt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('santander.csv', nrows = 20000)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checando a distribuição da variável alvo\n",
    "print(data.TARGET.value_counts())\n",
    "print(\"\\nConseção de Crédito representam {:.2f}% Do Dataset.\\n\".format((data[data.TARGET == 1].shape[0] / data.shape[0]) * 100))\n",
    "\n",
    "# plotando gráfico de barras\n",
    "fig, ax = plt.subplots()\n",
    "sns.countplot('TARGET', data=data, ax=ax)\n",
    "ax.set_title('Distribuição Das Classes')\n",
    "plt.plot()\n",
    "plt.savefig('original_dist.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('TARGET', axis = 1)\n",
    "y = data['TARGET']\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0, stratify = y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balanceando os Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aplicando o UnderSampler\n",
    "rus = RandomUnderSampler()\n",
    "X_rus_train, y_rus_train = rus.fit_sample(X_train, y_train)\n",
    "\n",
    "# checando o balanceamento das classes\n",
    "print(pd.Series(y_rus_train).value_counts())\n",
    "\n",
    "# plotando a nova distribuição das classes\n",
    "sns_plot = sns.countplot(y_rus_train);\n",
    "plt.savefig(\"balanced.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remoção de parâmetros constantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constant_filter = VarianceThreshold(threshold=0)\n",
    "constant_filter.fit(X_rus_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parâmetros constantes\n",
    "constant_filter.get_support().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removendo os parâmetros constantes\n",
    "X_train_filter = constant_filter.transform(X_rus_train)\n",
    "X_test_filter = constant_filter.transform(X_test)\n",
    "\n",
    "X_train_filter.shape, X_test_filter.shape, X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remoção de Parâmetros Semi-Constantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quasi_constant_filter = VarianceThreshold(threshold=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quasi_constant_filter.fit(X_train_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parâmetros Semi-constantes\n",
    "quasi_constant_filter.get_support().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removendo os parâmetros Semi-constantes\n",
    "X_train_quasi_filter = quasi_constant_filter.transform(X_train_filter)\n",
    "X_test_quasi_filter = quasi_constant_filter.transform(X_test_filter)\n",
    "\n",
    "X_train_quasi_filter.shape, X_test_quasi_filter.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parâmetros Duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_T = X_train_quasi_filter.T\n",
    "X_test_T = X_test_quasi_filter.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_T = pd.DataFrame(X_train_T)\n",
    "X_test_T = pd.DataFrame(X_test_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_T.shape, X_test_T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Duplicados\n",
    "X_train_T.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicated_features = X_train_T.duplicated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecionando os Parâmetros que devem ficar ou não\n",
    "features_to_keep = [not index for index in duplicated_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_unique = X_train_T[features_to_keep].T\n",
    "X_test_unique = X_test_T[features_to_keep].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_unique.shape, X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criando modelo e comparando as performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_randomForest(X_train, X_test, y_train, y_test):\n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=0, n_jobs=-1)\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred = rf.predict(X_test)\n",
    "    print(\"Classification Report\")\n",
    "    print(metrics.classification_report(y_test, y_pred, labels = [1, 0],digits=4))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#Modelo com os dados balanceados\n",
    "run_randomForest(X_train_unique, X_test_unique, y_rus_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "run_randomForest(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fica fácil ver que os dados balanceados e com a seleção de parâmetros mais simples tiveram bons resultados, analisemos:\n",
    "* A Precisão do modelo diminuiu para casos onde há concessão de crédito, tornando o modelo mais conservador.\n",
    "* A Sensibilidade (Recall) ficou mais equilibrada e melhorou significativamente para os casos onde há conseção de crédito."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## O que isso quer dizer na prática?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Com uma precisão menor para os casos positivos de concessão de crédito e um recall balanceado, o modelo será preciso tendo uma menor chance de conceder crédito a quem não deveria, mesmo que o cliente esteja enquadrado para receber o benefício. Isso é um bom resultado. Conceder crédito quando na verdade não deveria, pode ser uma grande perda de dinheiro."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusões"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ciência de Dados é um campo em expansão, boa parte do tempo de trabalho desse profissional é preparando os dados de maneira correta. Neste projeto, o intuito foi apresentar uma espécie de seleção de parâmetros para o estudo de concessão de crédito.\n",
    "\n",
    "Como projeto inicial, apenas o método mais simples foi implementado, existem muitos outros, que, na maioria das vezes, se complementam.\n",
    "\n",
    "Em próximos projetos, podemos implementar os outros modelos (Correlação de Person, X2, Informação Mútua, etc) para estudarmos o que acontece com os dados a cada etapa.\n",
    "\n",
    "    Obrigado!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referências\n",
    "* Gareth James; Daniela Witten; Trevor Hastie; Robert Tibshirani (2013). An Introduction to Statistical Learning. Springer. p. 204.\n",
    "* (Burns, 2000; M. Hill & A. Hill, 2000; Thomas & Nelson, 1996). Sin.: Estatística Univariável (Dorsch et al., 2001); Estatística a uma dimensão (Dagnelie, n.d.).\n",
    "* Estatística Bivariável (Dorsch et al., 2001); Estatística a duas dimensões (Dagnelie, n.d.)\n",
    "* Estatística Multivariável (Dorsch et al., 2001); Estatística a três ou mais dimensões (Dagnelie, n.d.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sites\n",
    "* https://en.wikipedia.org/wiki/Feature_selection\n",
    "* https://alexandreramos.blogs.sapo.pt/7901.html\n",
    "* https://sigmoidal.ai/como-lidar-com-dados-desbalanceados/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
